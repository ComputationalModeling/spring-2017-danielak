{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework \\#4 - SOLUTIONS\n",
    "\n",
    "This notebook is due on **Friday, November 18th, 2016 at 11:59 p.m.**.  Please make sure to get started early, and come by the instructors' office hours if you have any questions.  Office hours and locations can be found in the course syllabus.  **IMPORTANT:** While it's fine if you talk to other people in class about this homework - and in fact we encourage it! - you are responsible for creating the  solutions for this homework on your own, and each student must submit their own homework assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FOR THIS HOMEWORK:** In addition to the correctness of your answers, we will be grading you on:\n",
    "\n",
    "1. The quality of your code\n",
    "2. The correctness of your code\n",
    "3. Whether your code runs.\n",
    "\n",
    "To that end:\n",
    "\n",
    "1. Code quality: make sure that you use functions whenever possible, use descriptive variable names, and use comments to explain what your code does as well as function properties (including what arguments they take, what they do, and what they return).\n",
    "2. Whether your code runs: prior to submitting your homework assignment, re-run the entire notebook and test it.  Go to the \"kernel\" menu, select \"Restart\", and then click \"clear all outputs and restart.\"  Then, go to the \"Cell\" menu and choose \"Run all\" to ensure that your code produces the correct results.  **We will take off points for code that does not work correctly when we run it!**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOLUTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Section 1: The 1D Schelling model\n",
    "\n",
    "**Schelling's model for happiness:** Recall that in a 1D line of stars and zeros (to use Schelling's terminology), an element is \"happy\" if at least half of its neighbors (defined as the four elements to the left and four elements to the right) are like it, and \"unhappy\" otherwise.  For those near the end of the line the rule is that, of the four neighbors on the side toward the center plus the one, two or three outboard neighbors, at least half must be like oneself.\n",
    "\n",
    "Your assignment is to implement the Schelling model **exactly as described in the in-class project** using zeros and ones to indicate the two types of elements.  As with Schelling's original paper, you will play twice through the entire list, moving each element in a row (possibly moving a given element multiple times if it goes to the right).  Print out the state of the list at each step so that you can see how the solution evolves.\n",
    "\n",
    "Break up your code into functions whenever possible, and add comments to each function and to the rest of the code to make sure that we know what's going on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "def initialize_list(array_size=32, randseed=8675309):\n",
    "    '''\n",
    "    This function optionally takes in an array size and random seed\n",
    "    and returns the initial neighborhood that we're going to start \n",
    "    from - a string of zeros and ones.  If no arguments are given, it\n",
    "    defaults to the values specified.\n",
    "    '''\n",
    "\n",
    "    random.seed(randseed)\n",
    "    \n",
    "    initial_list = []\n",
    "\n",
    "    for i in range(array_size):\n",
    "        initial_list.append(random.randint(0,1))\n",
    "\n",
    "    return initial_list\n",
    "\n",
    "def is_happy(my_list, my_value, my_index):\n",
    "    '''\n",
    "    This function assumes that my_list has a value (my_value)\n",
    "    popped out of it already, and checkes to see if my_value\n",
    "    would be happy in my_list at index my_index.  It returns\n",
    "    'True' if happy and 'False' if unhappy under those circumstances.\n",
    "    '''\n",
    "\n",
    "    # do some error-checking (is the index within the allowed range?)\n",
    "    if my_index < 0 or my_index > len(my_list):\n",
    "        print(\"you've made an indexing error!\", my_index)\n",
    "        \n",
    "    start = my_index-4 # start 4 to the left\n",
    "    end = my_index+4   # end 3 to the right b/c we count the value at my_index too\n",
    "    \n",
    "    # if the starting value is out of bounds, fix it\n",
    "    if start < 0:\n",
    "        start = 0\n",
    "    \n",
    "    # if the ending value is out of bounds, fix it.  note that we want to go to \n",
    "    # len(list), not len(list)-1, because range() goes to 1 before the end of \n",
    "    # the range!\n",
    "    if end > len(my_list):\n",
    "        end = len(my_list)\n",
    "\n",
    "    # keep track of the neighbors that are like me\n",
    "    neighbors_like_me = 0\n",
    "    \n",
    "    # keep track of total neighbors\n",
    "    total_neighbors = 0\n",
    "    \n",
    "    # loop over the specified range\n",
    "    for i in range(start,end):\n",
    "        if my_list[i] == my_value:  # if this neighbor is like me, keep track of that\n",
    "            neighbors_like_me += 1\n",
    "        total_neighbors+=1  # also keep track of total neighbors\n",
    "    \n",
    "    # happy if at least half are like me, unhappy otherwise\n",
    "    # note: it's *at least* half because we're not double-counting our\n",
    "    # own value\n",
    "    if neighbors_like_me/total_neighbors >= 0.5:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def where_to_move(my_list, my_value, my_index):\n",
    "    '''\n",
    "    Given a neighborhood (my_list), a value (my_value), and the index\n",
    "    that it started at (my_index), figure out where to move my_value\n",
    "    so that it's happy.  This assumes that my_value is unhappy where it \n",
    "    is, by the way!  This function then returns the index where my_value\n",
    "    should move to in order to be happy.\n",
    "    '''\n",
    "\n",
    "    # this block of code steps to the left to see where (if anywhere) it's \n",
    "    # happy to the left.  If it continues to be unhappy, it'll stop when it\n",
    "    # is about to step off the end of the list.\n",
    "    left_index=my_index-1\n",
    "    left_happy=False\n",
    "    \n",
    "    while left_happy==False and left_index >= 0:\n",
    "        left_happy = is_happy(my_list,my_value,left_index)\n",
    "        if left_happy==False:\n",
    "            left_index -= 1\n",
    "    \n",
    "    # as above, but to the right.\n",
    "    right_index=my_index+1\n",
    "    right_happy=False\n",
    "\n",
    "    while right_happy==False and right_index < len(my_list):\n",
    "        right_happy = is_happy(my_list,my_value,right_index)\n",
    "        if right_happy==False:\n",
    "            right_index += 1\n",
    "\n",
    "    # now we figure out where the new index should be!\n",
    "    \n",
    "    if left_index < 0 and right_index < len(my_list):\n",
    "        # can't be happy to the left; only possible answer is right_index\n",
    "        new_index = right_index\n",
    "        \n",
    "    elif left_index >= 0 and right_index > len(my_list):  \n",
    "        # can't be happy to the right; only possible answer is left_index\n",
    "        new_index = left_index\n",
    "        \n",
    "    elif left_index >= 0 and right_index <= len(my_list): \n",
    "        # we're within bounds, so now check to see which side is closer.\n",
    "        # if they're the same we move it to the left.  (This was never specified\n",
    "        # by Schelling, so we have to make a choice on that.)\n",
    "        if math.fabs(left_index-my_index) > math.fabs(right_index-my_index):\n",
    "            new_index = right_index\n",
    "        else:\n",
    "            new_index = left_index        \n",
    "    else:\n",
    "        # this should only ever be called if something goes horribly wrong.\n",
    "        print(\"something has gone wrong in where_to_move!\")\n",
    "    \n",
    "    return new_index;\n",
    "\n",
    "def neighborhood_print(neighborhood, note=''):\n",
    "    '''\n",
    "    This is a convenience function to take our neighborhood list,\n",
    "    make a string of stars and zeros out of it, and print the string\n",
    "    plus optional text at the end.  It's not necessary but it looks pretty.  \n",
    "    '''\n",
    "    \n",
    "    neighborstring=''\n",
    "\n",
    "    for i in range(len(neighborhood)):\n",
    "        if(neighborhood[i]) > 0:\n",
    "            neighborstring += '*'\n",
    "        else:\n",
    "            neighborstring += '0'\n",
    "    \n",
    "    # make sure optional text is a string\n",
    "    if type(note)!=str:\n",
    "        note = str(note)\n",
    "    \n",
    "    # add an extra space to make it look nice!\n",
    "    if note != '':\n",
    "        note = ' ' + note\n",
    "        \n",
    "    neighborstring += note\n",
    "    \n",
    "    print(neighborstring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize list to defaults\n",
    "neighborhood = initialize_list(array_size=32)\n",
    "\n",
    "neighborhood_print(neighborhood, 'initial state')\n",
    "\n",
    "# do 2 loops over the list\n",
    "for i in range(2):\n",
    "\n",
    "    this_index = 0 \n",
    "\n",
    "    # step through the neighborhood once\n",
    "    while this_index < len(neighborhood):\n",
    "        \n",
    "        this_val = neighborhood.pop(this_index)\n",
    "\n",
    "        if is_happy(neighborhood,this_val,this_index):\n",
    "            # if we're happy where we are, don't change anything!\n",
    "            neighborhood.insert(this_index,this_val)\n",
    "            \n",
    "        else:\n",
    "            # we're unhappy; we need to figure out where to move and then move.\n",
    "            new_index = where_to_move(neighborhood,this_val,this_index)\n",
    "            neighborhood.insert(new_index,this_val)\n",
    "\n",
    "        neighborhood_print(neighborhood, this_index)\n",
    "\n",
    "        # increment this_index or we'll never stop looping\n",
    "        this_index += 1\n",
    "\n",
    "# print out the final state, just to see what it's like.\n",
    "neighborhood_print(neighborhood, 'final state!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(neighborhood,'ro')\n",
    "plt.xlim(-2,len(neighborhood)+1)\n",
    "plt.ylim(-0.1,1.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Section 2: Wrapping up our twitter analysis\n",
    "\n",
    "In this part of the homework, we're going to extend our analysis of the tweets of the presidential candidates (well, by the time you're actually coding this up, the president-to-be and their defeated opponent).  We're going to do a few things:\n",
    "\n",
    "1. Clean the data more comprehensively.\n",
    "2. Examine the candidates' tweeting styles in a more in-depth fashion.\n",
    "3. See how often the candidates refer to each other, and when they do refer to each other, is it positive, negative, or neutral?\n",
    "\n",
    "The cells that are immediately below this download the various files needed for this project, and then load the two files of tweets into huge strings named `clinton_tweets` and `trump_tweets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download the files\n",
    "import urllib.request\n",
    "\n",
    "files=['negative.txt','positive.txt']\n",
    "path='http://www.unc.edu/~ncaren/haphazard/'\n",
    "for file_name in files:\n",
    "    urllib.request.urlretrieve(path+file_name,file_name)\n",
    "    \n",
    "files=['HillaryClinton_tweets.txt','realDonaldTrump_tweets.txt']\n",
    "path='https://raw.githubusercontent.com/bwoshea/CMSE201_datasets/master/pres_tweets/'\n",
    "for file_name in files:\n",
    "    urllib.request.urlretrieve(path+file_name,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Now we open up the files.  Note that the 'encoding=\"utf8\"' portion\n",
    "is to take care of the fact that some windows machines have a hard \n",
    "time reading the text files generated on Mac and Linux computers.\n",
    "'''\n",
    "clinton_tweets = open(\"HillaryClinton_tweets.txt\",encoding=\"utf8\").read()\n",
    "trump_tweets = open(\"realDonaldTrump_tweets.txt\",encoding=\"utf8\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data\n",
    "\n",
    "We want to do a more comprehensive job cleaning the data than we did in class. We still want to do that too, though!  In particular, in addition to making all of the words lower case and removing punctuation, we want to remove words corresponding to hash tags (words starting with a pound sign, \\#) or websites (words starting with \"http\"), and any empty strings (an empty string looks like this: '').\n",
    "\n",
    "In the space below, you are given a test tweet that has capitalizations, punctuation, hash tags, and that will have empty strings when split into words.  **Write a function** that takes a tweet as an argument, cleans it, and returns a list of words.  Demonstrate that this function works by using it to clean the test tweet and print out the returned words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_tweet = \" Here is My test TWEET!!!?! #whoah #so_much_election #cmserocks   http://whoahdude.com \"\n",
    "\n",
    "words = test_tweet.split(' ')\n",
    "\n",
    "print(\"the words in the uncleaned test tweet are:\", words)\n",
    "\n",
    "# put your code here!\n",
    "from string import punctuation\n",
    "\n",
    "def tweet_cleaner(tweet_to_clean):\n",
    "    '''\n",
    "    tweet cleaner.  takes in a string that is a tweet full of messy words, \n",
    "    returns a list that has removed the hash tags, lowercased everything,\n",
    "    and removed all punctuation.  The order that this happens is very important!\n",
    "    '''\n",
    "\n",
    "    # make everything lowercase\n",
    "    lowercase = tweet_to_clean.lower()\n",
    "    \n",
    "    # split into a list (still has hashtags and punctuation, though)\n",
    "    uncleaned_words = lowercase.split()\n",
    "\n",
    "    # empty list - fill with words that aren't hash tags\n",
    "    no_hashtags = []\n",
    "    \n",
    "    # loop through words.  If word starts with a #, it's a hash tag.  \n",
    "    # if it does NOT start with a #, append it to no_hashtags\n",
    "    for word in uncleaned_words:\n",
    "        if word[0] != '#' and word[0:4] != 'http':\n",
    "            no_hashtags.append(word)\n",
    "         \n",
    "    # empty list - fill with words that have been cleaned of punctuation\n",
    "    no_punctuation = []\n",
    "\n",
    "    # loop through words, clean each word of punctuation, and then append\n",
    "    # it to the no_puncutation list.\n",
    "    for word in no_hashtags:\n",
    "        for p in punctuation:\n",
    "            word=word.replace(p,'')\n",
    "        no_punctuation.append(word)\n",
    "        \n",
    "    # at this point our dirty, dirty string has been turned into a \n",
    "    # clean, clean list!\n",
    "    return no_punctuation\n",
    "    \n",
    "list_of_words = tweet_cleaner(test_tweet)\n",
    "\n",
    "print(\"cleaned test tweet:\", list_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more comprehensive examination of the candidates' twitter styles\n",
    "\n",
    "Now that we've figured out how to clean the tweets, we're going to do a more in-depth analysis of the candidates' writing styles (or, more accurately, the styles of the candidates and their campaign staff - not all of the tweets come from the candidates themselves).  In particular, we want to determine:\n",
    "\n",
    "1. What is the **distribution of word lengths** that each candidate uses?  The average length of words used is one way to estimate the sophistication of writing - longer words may suggest more complex thoughts.\n",
    "2. Which candidate has used **a larger vocabulary** in their tweets?  In other words, which candidate uses more distinct or unique words, and thus uses less repetition of individual words?  As with word length, a larger vocabulary may suggest more complex thoughts.\n",
    "\n",
    "**Hint:** Consider using a [dictionary](https://docs.python.org/3/tutorial/datastructures.html#dictionaries) to help address the second question!  (And see the tutorial we have provided on dictionaries.)\n",
    "\n",
    "**In the cell below, summarize what you've learned** about the candidates' tweeting styles.  Use the cell below that (and any additional cells you need) to include the code, figures, etc. that you needed to determine your answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** The distribution of word lengths is basically the same between the two candidates.  When you examine the number of words, the Clinton campain uses about 10% more distinct words than the Trump campaign. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put your code and figures here.  Add additional cells if necessary!\n",
    "\n",
    "def analyze_candidate_tweets(tweets):\n",
    "    '''\n",
    "    Analyzes candidate tweets to determine (1) the distribution of word lengths\n",
    "    and (2) the number of separate words, and return both as dictionaries of the\n",
    "    number of words of a given letter length, and then the number of words and \n",
    "    the times each is used.\n",
    "    '''\n",
    "    \n",
    "    tweets_list = tweets.split('\\n')\n",
    "\n",
    "    # make dictionaries\n",
    "    word_lengths = {}\n",
    "    word_dictionary = {}\n",
    "    \n",
    "    # loop over tweets\n",
    "    for tweet in tweets_list:\n",
    "        \n",
    "        # for each tweet, make a cleaned list of words\n",
    "        word_list = tweet_cleaner(tweet)\n",
    "\n",
    "        # loop over words in the tweet\n",
    "        for word in word_list:\n",
    "            # how long is the word?\n",
    "            wordsize = len(word)\n",
    "            \n",
    "            # increment the word count if it's in the dictionary already;\n",
    "            # add it if not.\n",
    "            if word in word_dictionary:\n",
    "                word_dictionary[word] += 1\n",
    "            else:\n",
    "                word_dictionary[word] = 1\n",
    "            \n",
    "            # increment the number of words at that size if it's already in the \n",
    "            # dictioanry; add it if not.\n",
    "            if wordsize in word_lengths:\n",
    "                word_lengths[wordsize] += 1\n",
    "            else:\n",
    "                word_lengths[wordsize] = 1\n",
    "            \n",
    "    # return our two dictionaries    \n",
    "    return word_lengths, word_dictionary \n",
    "\n",
    "# get clinton info\n",
    "clinton_word_lengths, clinton_word_dictionary = analyze_candidate_tweets(clinton_tweets)\n",
    "\n",
    "print(\"Number of Clinton words: \", len(clinton_word_dictionary))\n",
    "\n",
    "# get trump info\n",
    "trump_word_lengths, trump_word_dictionary = analyze_candidate_tweets(trump_tweets)\n",
    "\n",
    "print(\"Number of Trump words: \", len(trump_word_dictionary))\n",
    "\n",
    "plt.plot(list(trump_word_lengths.keys()), list(trump_word_lengths.values()),'r-')\n",
    "plt.plot(list(clinton_word_lengths.keys()), list(clinton_word_lengths.values()),'b-')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do the candidates talk about each other?\n",
    "\n",
    "We're now going to examine how the candidates have talked about each other.  Go through their list of tweets and find all of the incidences where they refer to the other candidate, and determine:\n",
    "\n",
    "1. If they typically refer to their opponent using positive words, negative words, both positive and negative words, or neither?\n",
    "2. Keep track of all of the positive and negative words that they use to refer to their opponent.  What are the most common positive and negative words that they use about their opponent?\n",
    "\n",
    "**Hint:** What words do the candidates use to refer to each other?  By their first names, last names, Twitter handles, or something else?\n",
    "\n",
    "**In the cell below, summarize what you've learned** about how the candidates talk about each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "Clinton refers to Trump about 25% of the time; the largest fraction of mentions is \"neither positive or negative\" followed by \"positive\" and then \"negative\".  The most common positive words that Clinton uses when referring to Trump are help, just, will and great.  The most common negative words are racist, lie, against, unqalified, and lying.\n",
    "\n",
    "Trump refers to Clinton about 15% of the time; the largest fraction of mentions is \"both positive and negative\" followed by \"negative\" and then \"neither\".  The most common positive words that Trump uses when referring to Clinton are even, will, just, deal, wow.  The most common negative words are crooked (almost 200 times!), lie, bad, corrupt, wrong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put your code and figures here.  Add additional cells if necessary!\n",
    "\n",
    "# get list of positive words (previously downloaded)\n",
    "pos_sent = open(\"positive.txt\").read()\n",
    "positive_words=pos_sent.split('\\n')\n",
    "\n",
    "# get list of negative words (previously downloaded)\n",
    "neg_sent = open(\"negative.txt\").read()\n",
    "negative_words=neg_sent.split('\\n')\n",
    "\n",
    "# guess at the names clinton and trump use to refer to each other\n",
    "clinton_names = ['hillaryclinton', 'hillary', 'hilary', 'clinton']\n",
    "trump_names = ['realdonaldtrump','donald','trump']\n",
    "\n",
    "def candidate_referral(tweets, opponent_names, positive_words, negative_words):\n",
    "    '''\n",
    "    This function examines each candidate's tweets to see how often they refer to\n",
    "    their opponent, and if so how positive/negative that is, and to figure out the words used.\n",
    "    \n",
    "    Function takes in a list of tweets from a candidate, the names that they use to refer to\n",
    "    their opponent, and lists of positive and negative words.\n",
    "    \n",
    "    Outputs a dictionary of info about the tweets (total tweets, mentions, pos. mentions, neg. mentions, etc.),\n",
    "    dictionaries of the positive and negative words used, and lists of EVERY positive and negative\n",
    "    word used (even if they are repeated).  The lists are used for word clouds later.\n",
    "    '''\n",
    "    \n",
    "    # split up our tweets\n",
    "    tweets_list = tweets.split('\\n')\n",
    "    \n",
    "    # dictionaries of positive and negative words we'll use\n",
    "    pos_words_used = {}\n",
    "    neg_words_used = {}\n",
    "    \n",
    "    # lists to keep track of positive and negative words used\n",
    "    pos_words_list = []\n",
    "    neg_words_list = []\n",
    "    \n",
    "    # dictionary to keep track of tweet statistics\n",
    "    tweet_info_dict = {'positive':0, 'negative':0, 'both':0, 'neither':0, \n",
    "                       'total_tweets':0, 'opponent_mentions':0}\n",
    "    \n",
    "    # loop over tweets\n",
    "    for tweet in tweets_list:\n",
    "\n",
    "        # is the candidate mentioned in this tweek?\n",
    "        is_opponent_mentioned = 0\n",
    "        \n",
    "        # clean the tweet and return list of words\n",
    "        word_list = tweet_cleaner(tweet)\n",
    "\n",
    "        # loop over words in word list\n",
    "        for word in word_list:\n",
    "\n",
    "            # check to see if the opponent is mentioned\n",
    "            if word in opponent_names:\n",
    "                is_opponent_mentioned += 1\n",
    "        \n",
    "        # if the opponent is mentioned, now let's figure some stuff out.\n",
    "        if is_opponent_mentioned > 0:\n",
    "\n",
    "            # keep track of mentions\n",
    "            tweet_info_dict['opponent_mentions'] += 1\n",
    "\n",
    "            negative = 0\n",
    "            positive = 0\n",
    "            \n",
    "            # loop over words in tweet again\n",
    "            for word in word_list:\n",
    "\n",
    "                # if the word is on our list of positive words, add that up, \n",
    "                # and keep track of the word in both the dict and list\n",
    "                if word in positive_words:\n",
    "                    positive += 1\n",
    "                    pos_words_list.append(word)\n",
    "                    if word in pos_words_used:\n",
    "                        pos_words_used[word] += 1\n",
    "                    else:\n",
    "                        pos_words_used[word] = 1\n",
    "                        \n",
    "                # do the same for negative words (as above)\n",
    "                if word in negative_words:\n",
    "                    negative += 1\n",
    "                    neg_words_list.append(word)\n",
    "                    if word in neg_words_used:\n",
    "                        neg_words_used[word] += 1\n",
    "                    else:\n",
    "                        neg_words_used[word] = 1\n",
    "\n",
    "            # logic to figure out if it's a positive, negative, both pos/neg, or neither mention\n",
    "            if positive > 0 and negative == 0:\n",
    "                tweet_info_dict['positive'] += 1\n",
    "\n",
    "            if positive == 0 and negative > 0:\n",
    "                tweet_info_dict['negative'] += 1\n",
    "\n",
    "            if positive == 0 and negative == 0:\n",
    "                tweet_info_dict['neither'] += 1\n",
    "                \n",
    "            if positive > 0 and negative > 0:\n",
    "                tweet_info_dict['both'] += 1\n",
    "\n",
    "        # no matter what, increment the total number of tweets\n",
    "        tweet_info_dict['total_tweets'] += 1\n",
    "\n",
    "    # return all the info.\n",
    "    return tweet_info_dict, pos_words_used, neg_words_used, pos_words_list, neg_words_list\n",
    "    \n",
    "# collect info about clinton mentions\n",
    "clinton_info_dict, clinton_poswords, clinton_negwords, clinton_poswords_list, clinton_negwords_list = candidate_referral(clinton_tweets, trump_names, \n",
    "                                                                           positive_words, negative_words)\n",
    "\n",
    "# collect info about trump mentions\n",
    "trump_info_dict, trump_poswords, trump_negwords, trump_poswords_list, trump_negwords_list = candidate_referral(trump_tweets, clinton_names, \n",
    "                                                                           positive_words, negative_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print out some info; I'm going to extract words by hand.\n",
    "print(\"CLINTON POSITIVE WORDS:\", clinton_poswords,\"\\n\\n\")\n",
    "print(\"CLINTON NEGATIVE WORDS:\", clinton_negwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print out some info; I'm going to extract words by hand.\n",
    "print(\"TRUMP POSITIVE WORDS:\", trump_poswords,\"\\n\\n\")\n",
    "print(\"TRUMP NEGATIVE WORDS:\", trump_negwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pie chart for Clinton referrals to Trump\n",
    "\n",
    "print(\"\\n\\n******** CLINTON (referrals to Trump) ********\\n\\n\")\n",
    "print(clinton_info_dict)\n",
    "\n",
    "# The slices will be ordered and plotted counter-clockwise.\n",
    "labels = 'positive', 'both', 'negative', 'neither'\n",
    "sizes = [clinton_info_dict['positive'], clinton_info_dict['both'],\n",
    "         clinton_info_dict['negative'], clinton_info_dict['neither']]\n",
    "colors = ['yellowgreen', 'yellow','red',  'lightcyan']\n",
    "explode = (0.1, 0, 0.1, 0)  \n",
    "\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pie chart for Trump referrals to Clinton\n",
    "\n",
    "print(\"\\n\\n******** TRUMP (referrals to Clinton) ********\\n\\n\")\n",
    "print(trump_info_dict)\n",
    "\n",
    "# The slices will be ordered and plotted counter-clockwise.\n",
    "labels = 'positive', 'both', 'negative', 'neither'\n",
    "sizes = [trump_info_dict['positive'], trump_info_dict['both'],\n",
    "         trump_info_dict['negative'], trump_info_dict['neither']]\n",
    "colors = ['yellowgreen', 'yellow','red',  'lightcyan']\n",
    "explode = (0.1, 0, 0.1, 0)  \n",
    "\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A different way of visualizing the data\n",
    "\n",
    "Finally, we're going to visualize the positive and negative words that the candidates use to describe each other using [word clouds](http://www.boostlabs.com/what-are-word-clouds-value-simple-visualizations/).  In a word cloud, the more a specific word appears in some source of textual data, the larger and bolder the word appears in the cloud.  While this is not a perfectly representative way of visualizing data, it gives a good sense of what words are commonly used.  So, here's how we will proceed:\n",
    "\n",
    "First, install some software that can be used to [generate word clouds](https://pypi.python.org/pypi/wordcloud) by typing:\n",
    "\n",
    "`!pip install wordcloud`\n",
    "\n",
    "in a code cell and wait for the code to install, which may take a minute or two.  Make sure to include the exclamation point.  You only have to do this once per computer!\n",
    "\n",
    "Then, generate separate lists of the positive and negative words that each candidate uses to refer to their opponent (making sure to keep the duplicate words in the list - you need this for the word cloud!).  You'll take each list, convert it into a string, clean up the string, and then make it into a word cloud.  This is kind of a pain, so we're including example code below.  Note that we are only showing you how to generate a simple word cloud - to make a more complicated one, look at the [documentation](https://github.com/amueller/word_cloud)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# imports the word cloud module\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# we assume you have a list called candidate_word_list_positive,\n",
    "# which we then convert into a string\n",
    "candidate_positive_words = str(candidate_word_list_positive)\n",
    "\n",
    "# take that string and clean out all of the list-y things by replacing them with blank spaces.\n",
    "candidate_positive_words = candidate_positive_words.replace('\\'','').replace(',','').replace('\\\"','').replace('[','').replace(']','')\n",
    "\n",
    "# now we make the word cloud, using only the 60 most common words and keeping the\n",
    "# font size relatively small.\n",
    "wordcloud = WordCloud(background_color=\"white\",max_words=60, max_font_size=40).generate(candidate_positive_words)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# positive words clinton uses in mentions of trump\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "clinton_positive_words = str(clinton_poswords_list)\n",
    "clinton_positive_words = clinton_positive_words.replace('\\'','').replace(',','').replace('\\\"','').replace('[','').replace(']','')\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\",max_words=60, max_font_size=40).generate(clinton_positive_words)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# negative words clinton uses in mentions of trump\n",
    "clinton_negative_words = str(clinton_negwords_list)\n",
    "clinton_negative_words = clinton_negative_words.replace('\\'','').replace(',','').replace('\\\"','').replace('[','').replace(']','')\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\",max_words=60, max_font_size=40).generate(clinton_negative_words)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# positive words trump uses in mentions of clinton\n",
    "trump_positive_words = str(trump_poswords_list)\n",
    "trump_positive_words = trump_positive_words.replace('\\'','').replace(',','').replace('\\\"','').replace('[','').replace(']','')\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\",max_words=60, max_font_size=40).generate(trump_positive_words)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# negative words trump uses in mentions of clinton\n",
    "trump_negative_words = str(trump_negwords_list)\n",
    "trump_negative_words = trump_negative_words.replace('\\'','').replace(',','').replace('\\\"','').replace('[','').replace(']','')\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\",max_words=60, max_font_size=40).generate(trump_negative_words)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Section 3: Feedback (required!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\n",
    "\"\"\"\n",
    "<iframe\n",
    "    src=\"https://goo.gl/forms/8HNgy9DipNjx0Xe42?embedded=true\" \n",
    "    width=\"80%\" \n",
    "    height=\"1200px\" \n",
    "    frameborder=\"0\" \n",
    "    marginheight=\"0\" \n",
    "    marginwidth=\"0\">\n",
    "    Loading...\n",
    "</iframe>\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Congratulations, you're done!\n",
    "\n",
    "## How to submit this assignment\n",
    "\n",
    "Log into the course Desire2Learn website (d2l.msu.edu) and go to the \"Homework assignments\" folder.  There will be a dropbox labeled \"Homework 4\".  Upload this notebook there. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
